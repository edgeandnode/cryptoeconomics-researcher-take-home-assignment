{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4eafb02",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "Firstly, congratulations on advancing this far in the hiring process! The fact that you are reading this means that E&N has recognized your potential and is excited to test your skills further. We hope you find this task both challenging and enjoyable. Please feel free to share any feedback during your upcoming skills interview.\n",
    "\n",
    "### Task Overview\n",
    "\n",
    "This task is designed to test your problem-solving abilities and your familiarity with computational notebooks. While it is not intended to be easy, we are not expecting perfection. We value clear, concise documentation and a genuine attempt to produce functional code.\n",
    "\n",
    "**Background:** In the future, when a data consumer (aka developer/customer) comes to The Graph and pays for data to be indexed,  a gateway will need to allocate a group of indexers (service providers) to index their subgraph. What follows is written from the point of view of a gateway operator (such as Edge & Node). Indexers are given a score that shows how suitable we think they are to serve data on each chain. After a score has been assigned to all indexers on each chain we use indexersâ€™ scores to inform selection probability of receiving an indexing agreement for each chain. An indexing agreement is an agreement that means the indexer will provide indexing services and we will pay the indexer for their indexing services (the customer pays us and we act as an intermediary). An indexer's aim is to receive as many indexing agreements as they can in order to maximise the income they generate from their indexing activities. Indexers that provide higher quality of service (QoS) at lower prices will increase their chances of receiving indexing agreements.\n",
    "\n",
    "A single indexing agreement contains information such as the price the indexer will get paid, and what data they have to make available to be queried. We can award contracts that specify the portion of data which has to be made available to several indexers, instead of a single indexer. By giving a group of indexers an indexing agreement instead of allocating that agreement to only 1 indexer we are aiming to provide customers (developers/data consumers) with a higher quality of service. The rationale is that if a single indexer inside the group was to have issues, then other indexers in the group can continue to operate. Awarding indexing agreements to a group should help to improve quality of service, reduce query latency, increase data uptime and increase query success rate, among other things that a consumer may find valuable. However the QoS that a customer receives is a function of the indexers that are included in the group the customer is assigned. Your task is to figure out how to group indexers together for the best QoS for customers.\n",
    "\n",
    "In this task we have provided you with two CSV's containing an assortment of (simulated) indexers, where those indexers are located, what VPS provider the indexer is using, and the indexer's current scores for a variety of metrics. We have also already computed how many indexing agreements each indexer should receive based on their scores, for the next batch of 10,000 indexing agreements. To test your python skills we want you to group indexers into groups of 3 indexers per group. The catch is, we have lost our data that gives each indexer a overall score, so we'll also need your help to reassign a overall score to each indexer, this will help you to figure out the aggregate overall score of each group you assemble. Fortunately, we kept some of the information that we used to construct the indexer's overall scores. For example, in the 'Example_scores_df_skills_take_home.csv' you'll find indexer's stake_score, uptime_score, success_score and coeff_score. \n",
    "\n",
    "**stake_score** is a measure of how much GRT the indexer is staking relative to the query fees they're collecting, scaled between 0 and 1, where a higher score indicates the indexer is providing a high level of economic security relative to the revenue they are generating from serving queries.\n",
    "\n",
    "**uptime_score** is a measure of how often an indexer responds to a query from our gateway. It's scaled linearly between 0 and 1, where a score of 1 represents 100% uptime and a score of 0 represents 97% or less uptime. Therefore a score of 0.5 represents 98.5% uptime. \n",
    "\n",
    "**success_score** is a measure of how often an indexer *successfully* responds to a query from our gateway. It's scaled linearly between 0 and 1, where a score of 1 represents 100% uptime and a score of 0 represents 97% or less uptime. Therefore a score of 0.5 represents 98.5% uptime. \n",
    "\n",
    "**coeff_score** is a measure of how fast indexers are at responding to queries - this score was generated from a linear regression. It's normalised between 0 and 1 where a score of 1 means the indexer is the fastest at responding to queries and a score of 0 means the indexer is the slowest at responding to queries. Customers want low latency when they send a query to the network, because their applications may rely on them providing their users with accurate and timely data. \n",
    "\n",
    "**overall_score** is an aggregate score of the prior scores, but unfortunately we lost the data! Oops!\n",
    "\n",
    "The groups you create (in this hypothetical example) will be paid to index data for future customers, with each group having a chance to be awarded indexing agreements. When forming these groups, you should consider decentralisation and the overall quality of service (QoS) each group can provide. Another crucial factor is that the number of agreements allocated to the groups in which an indexer appears should sum up to the total number of agreements that indexer has been awarded for the batch. This ensures that, as groups are randomly selected to serve customers' data, the total number of agreements each indexer fulfils equilibrates to their targeted number over time. If you do decide to deviate from this requirement make sure to document your logic, as we are keen to understand your thought process.\n",
    "\n",
    "You should also think about what you are optimising for when creating the groups given the data you have available and efficient ways to complete this task without spending too much time on it, although if you want to focus on the quality of your submission you are free to spend more time wherever you think is appropriate. Your submission will be compared against other candidates so you should aim to do your best work, but don't stress about it, this is far from the only selection criteria for this role. Let us know if you have any problems with this assignment in your upcoming skills interview. We are looking forward to meeting you!\n",
    "\n",
    "\n",
    "### Key Points to Focus On\n",
    "\n",
    "1. **Optimization:** Aim to optimise the indexer groups you create. Randomly allocating indexers into groups of 3 will not score many points.\n",
    "2. **Documentation:** Ensure your code and your logic is well-documented where appropriate, making it easy to understand and follow.\n",
    "3. **Plots**: Attempt to demonstrate your work visually with graphs where appropriate. How you chose to do this is left for you to decide. You are not required to use python.\n",
    "4. **Optimization:** If possible, try to optimise the speed of your code execution. More care should be taken to perform sound analysis, than writing efficient code, however writing efficient code is also beneficial.\n",
    "\n",
    "You will notice that a start to the assignment has already been made, you are free to continue by adding to the existing code or start fresh with your own code. If you are having any trouble, or would like further clarity on anything, you can send as many emails as you like to samuel@edgeandnode.com, pablo@edgeandnode.com & rem@edgeandnode.com.\n",
    "\n",
    "We understand that candidates might have different time availability for take home challenges - we hope you can dedicate between 2 and 4 hours to solving this, and that you can present your solution in a week or two; if this will not work for you please let us know and we'll do our best to accommodate.\n",
    "\n",
    "We look forward to seeing your approach and solutions. Good luck!\n",
    "\n",
    "Please direct your submission to [samuel\\@edgeandnode.com](mailto:samuel@edgeandnode.com) (@MoonBoi9001 on GitHub), [pablo\\@edgeandnode.com](mailto:pablo@edgeandnode.com) (@pcarranzav) & [rem\\@edgeandnode.com](mailto:rem@edgeandnode.com)  (@RembrandK). You can create a private fork of this repository on GitHub, and add us as collaborators, or send us a compressed file with your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f67983",
   "metadata": {},
   "source": [
    "#### Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857d9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d384f03",
   "metadata": {},
   "source": [
    "#### Load the example data you have been given for this asignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "196c198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_df = pd.read_csv(\"Example_indexer_df_skills_take_home.csv\")\n",
    "scores_df = pd.read_csv(\"Example_scores_df_skills_take_home.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3210e3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexer</th>\n",
       "      <th>indexer_vps_provider</th>\n",
       "      <th>indexer_location</th>\n",
       "      <th>indexing_agreements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xbcfd8fadabb6cffba8fdfdd3aac9f478d82eacc2</td>\n",
       "      <td>AS24940 Hetzner Online GmbH</td>\n",
       "      <td>60,20</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1f7a67bbdea486fd31c62ef60de15adc5d9beffb</td>\n",
       "      <td>AS3170 VeloxServ Communications Ltd</td>\n",
       "      <td>60,0</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa7ff5a5dedbdbadd9e60797c2e07fbcedc8ef34f</td>\n",
       "      <td>AS24940 Hetzner Online GmbH</td>\n",
       "      <td>60,20</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa9aae95abfbbbeec6fee421684ddcbdfcfa8dcfa</td>\n",
       "      <td>AS13335 Cloudflare, Inc.</td>\n",
       "      <td>40,-120</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0x31cdacf1fcdcc4454e89b0cc1ec83de86bdb81f9</td>\n",
       "      <td>AS37153 Xneelo (Pty) Ltd</td>\n",
       "      <td>-20,20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0x110bc4d10bd862aed3bf6c2ebd9effd29c7f1ef8</td>\n",
       "      <td>AS13335 Cloudflare, Inc.</td>\n",
       "      <td>40,-120</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       indexer  \\\n",
       "0   0xbcfd8fadabb6cffba8fdfdd3aac9f478d82eacc2   \n",
       "1   0x1f7a67bbdea486fd31c62ef60de15adc5d9beffb   \n",
       "2   0xa7ff5a5dedbdbadd9e60797c2e07fbcedc8ef34f   \n",
       "3   0xa9aae95abfbbbeec6fee421684ddcbdfcfa8dcfa   \n",
       "0                                          ...   \n",
       "72  0x31cdacf1fcdcc4454e89b0cc1ec83de86bdb81f9   \n",
       "73  0x110bc4d10bd862aed3bf6c2ebd9effd29c7f1ef8   \n",
       "\n",
       "                   indexer_vps_provider indexer_location indexing_agreements  \n",
       "0           AS24940 Hetzner Online GmbH            60,20                 262  \n",
       "1   AS3170 VeloxServ Communications Ltd             60,0                 247  \n",
       "2           AS24940 Hetzner Online GmbH            60,20                 242  \n",
       "3              AS13335 Cloudflare, Inc.          40,-120                 234  \n",
       "0                                   ...              ...                 ...  \n",
       "72             AS37153 Xneelo (Pty) Ltd           -20,20                   7  \n",
       "73             AS13335 Cloudflare, Inc.          40,-120                   6  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 4 and last 2 rows of the indexer_df\n",
    "pd.concat([\n",
    "    indexer_df.head(4),\n",
    "    pd.DataFrame(['...'] * len(indexer_df.columns)).transpose().set_axis(indexer_df.columns, axis=1),\n",
    "    indexer_df.tail(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "299842f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexer</th>\n",
       "      <th>stake_score</th>\n",
       "      <th>uptime_score</th>\n",
       "      <th>success_score</th>\n",
       "      <th>coeff_score</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xbcfd8fadabb6cffba8fdfdd3aac9f478d82eacc2</td>\n",
       "      <td>0.848469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88395</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1f7a67bbdea486fd31c62ef60de15adc5d9beffb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.870472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa7ff5a5dedbdbadd9e60797c2e07fbcedc8ef34f</td>\n",
       "      <td>0.753762</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.892237</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa9aae95abfbbbeec6fee421684ddcbdfcfa8dcfa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.903438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0x31cdacf1fcdcc4454e89b0cc1ec83de86bdb81f9</td>\n",
       "      <td>0.532803</td>\n",
       "      <td>0.415333</td>\n",
       "      <td>0.415205</td>\n",
       "      <td>0.845812</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0x110bc4d10bd862aed3bf6c2ebd9effd29c7f1ef8</td>\n",
       "      <td>0.623717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886796</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       indexer stake_score uptime_score  \\\n",
       "0   0xbcfd8fadabb6cffba8fdfdd3aac9f478d82eacc2    0.848469          1.0   \n",
       "1   0x1f7a67bbdea486fd31c62ef60de15adc5d9beffb         NaN     0.999667   \n",
       "2   0xa7ff5a5dedbdbadd9e60797c2e07fbcedc8ef34f    0.753762     0.999667   \n",
       "3   0xa9aae95abfbbbeec6fee421684ddcbdfcfa8dcfa         NaN        0.964   \n",
       "0                                          ...         ...          ...   \n",
       "72  0x31cdacf1fcdcc4454e89b0cc1ec83de86bdb81f9    0.532803     0.415333   \n",
       "73  0x110bc4d10bd862aed3bf6c2ebd9effd29c7f1ef8    0.623717          0.0   \n",
       "\n",
       "   success_score coeff_score overall_score  \n",
       "0            1.0     0.88395           NaN  \n",
       "1       0.999722    0.870472           NaN  \n",
       "2       0.999696    0.892237           NaN  \n",
       "3       0.903438         1.0           NaN  \n",
       "0            ...         ...           ...  \n",
       "72      0.415205    0.845812           NaN  \n",
       "73           0.0    0.886796           NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 4 and last 2 rows of the scores_df\n",
    "pd.concat([\n",
    "    scores_df.head(4),\n",
    "    pd.DataFrame(['...'] * len(scores_df.columns)).transpose().set_axis(scores_df.columns, axis=1),\n",
    "    scores_df.tail(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8806e8",
   "metadata": {},
   "source": [
    "#### 1. Create a new df containing permutations of indexers from the indexer_df, give each permutation an overall_score that represents the performance of the group.\n",
    "#### 2. Add any further columns to this df that might be useful to determine how suitable the group is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15e7e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary's for quick lookups\n",
    "provider_dict = indexer_df.set_index('indexer')['indexer_vps_provider'].to_dict()\n",
    "loc_dict = indexer_df.set_index('indexer')['indexer_location'].to_dict()\n",
    "score_dict = scores_df.set_index('indexer')['overall_score'].to_dict()\n",
    "\n",
    "# Calculate Possible Groupings and Their Scores.\n",
    "groups = list(combinations(indexer_df['indexer'], 3))\n",
    "group_scores = [score_dict[x] + score_dict[y] + score_dict[z] for x, y, z in groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76514c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame({\n",
    "    \"group\": groups,\n",
    "    \"overall_score\": group_scores\n",
    "})\n",
    "\n",
    "# Filter out groups with too low scores. We already know that we wont be using them. \n",
    "# In this case any group with lower group score than the 1% percentile group score is removed.\n",
    "\n",
    "threshold_score = np.percentile(group_df['overall_score'], 1)\n",
    "group_df = group_df[group_df['overall_score'] > threshold_score].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab415d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [group, overall_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7319e9",
   "metadata": {},
   "source": [
    "#### Using your df above that contains permutations of indexers, their scores and their suitability, figure out which groups should receive the indexing agreements and how many agreements they should receive.\n",
    "\n",
    "#### You may want to formulate a linear programming problem, however you are free to tackle this however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd0a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034e2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407dabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e736e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb5f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264d7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf57f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
